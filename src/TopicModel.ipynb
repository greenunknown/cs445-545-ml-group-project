{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## implementing LDA with gensim\n",
    "1) import dataset\n",
    "2) preprocess text\n",
    "3) create gensim dictionary and corpus\n",
    "4) build the topic model\n",
    "5) analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this once\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from collections import defaultdict # for pos tag -> wordnet tag\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import Phrases # For adding n-grams\n",
    "from gensim import corpora, models, similarities \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform topic modelling with the help of nltk and gensim \n",
    "#\n",
    "class TopicModeler:\n",
    "    # Initialize an instance of the TopicModeler class\n",
    "    # params:\n",
    "    #   corpus<numpy.ndarray([string])>: A numpy array of strings, representing documents in a corpus\n",
    "    #   disp_interval<integer>: Display progess after each interval\n",
    "    #\n",
    "    def __init__(self, corpus, disp_interval=1000):\n",
    "        self.corpus = np.copy(corpus)\n",
    "        self.dictionary = None\n",
    "        self.model = None\n",
    "        self.disp_interval = disp_interval\n",
    "        self.N = np.shape(self.corpus)[0]\n",
    "        logging.info('Initialized a TopicModeler with corpus size N=' + str(self.N))\n",
    "        return\n",
    "        \n",
    "        \n",
    "    # Split the documents in the corpus into lists of raw tokens\n",
    "    # params:\n",
    "    #   disp_interval<integer>: Display progess after each interval\n",
    "    #\n",
    "    def tokenize(self, disp_interval=None):\n",
    "        if disp_interval == None:\n",
    "            disp_interval = self.disp_interval\n",
    "            \n",
    "        # Convert each document in the corpus into a list of tokens \n",
    "        for document in range(self.N):\n",
    "            if (document % disp_interval == 0):\n",
    "                logging.info('Performing tokenization: [' + str(document) + '/' + str(self.N) + ']')\n",
    "            self.corpus[document] = word_tokenize(self.corpus[document])\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Perform morphological normalization on the corpus as a list of raw tokens\n",
    "    # params:\n",
    "    #   norm<'lemma'|'stem'>: The form of morphological normalization to use\n",
    "    #   disp_interval<integer>: Display progess after each interval\n",
    "    #\n",
    "    def normalize(self, norm='lemma', disp_interval=None):\n",
    "        logging.info('Performing normalization.')\n",
    "        logging.debug('norm=' + str(norm))\n",
    "        if disp_interval == None:\n",
    "            disp_interval = self.disp_interval\n",
    "        \n",
    "        if (norm == 'lemma'):\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            \n",
    "            # Maps nltk pos tags into wordnet pos tags\n",
    "            tag_map = defaultdict(lambda : wordnet.NOUN)\n",
    "            tag_map['J'] = wordnet.ADJ\n",
    "            tag_map['V'] = wordnet.VERB\n",
    "            tag_map['R'] = wordnet.ADV\n",
    "            \n",
    "            for document in range(self.N):\n",
    "                if (document % disp_interval == 0):\n",
    "                    logging.info('Performing lemmatization: [' + str(document) + '/' + str(self.N) + ']')\n",
    "                self.corpus[document] = [lemmatizer.lemmatize(tagged_token[0], tag_map[tagged_token[1][0]])\n",
    "                            for tagged_token in pos_tag(self.corpus[document])]\n",
    "        elif (norm == 'stem'):\n",
    "            stemmer = PorterStemmer()\n",
    "            \n",
    "            for document in range(self.N):\n",
    "                if (document % disp_interval == 0):\n",
    "                    logging.info('Performing stemming: [' + str(document) + '/' + str(self.N) + ']')\n",
    "                self.corpus[document] = [stemmer.stem(token) for token in self.corpus[document]]\n",
    "        else:\n",
    "            logging.warning('Invalid parameter! Skipping normalization...')\n",
    "        return\n",
    "            \n",
    "        \n",
    "    # Filter out any tokens that are not within a specified string length\n",
    "    # params:\n",
    "    #   min_strlen<integer>: The minimum amount of chars a token can have\n",
    "    #   max_strlen<integer>: The maximum amount of chars a token can have\n",
    "    #\n",
    "    def filter_length(self, min_strlen=1, max_strlen=100):\n",
    "        logging.info('Filtering out tokens that are out of the length bounds.')\n",
    "        logging.debug('min_strlen=' + str(min_strlen))\n",
    "        logging.debug('max_strlen=' + str(max_strlen))\n",
    "        \n",
    "        self.corpus = [[token for token in document\n",
    "                            if len(token) >= min_strlen\n",
    "                            and len(token) <= max_strlen\n",
    "                       ] for document in self.corpus]\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Filter out any tokens that match a regular expression\n",
    "    # params:\n",
    "    #   pattern<raw string>: The regular expresstion to match\n",
    "    #\n",
    "    def filter_match(self, pattern):\n",
    "        logging.info('Filtering out tokens that match the regular expression: ' + str(pattern))\n",
    "        \n",
    "        self.corpus = [[token for token in document\n",
    "                            if re.search(pattern, token)\n",
    "                       ] for document in self.corpus]\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Lowercase all tokens\n",
    "    #\n",
    "    def lowercase(self):\n",
    "        logging.info('Converting all tokens to lowercase.')\n",
    "        self.corpus = [[token.lower() for token in document] for document in self.corpus]\n",
    "        return\n",
    "        \n",
    "        \n",
    "    # Add n-grams to the corpus\n",
    "    # params:\n",
    "    #   n<integer(2|3)>: The maximum length of the sequence of words to add to the corpus\n",
    "    #   min_count<integer>: The minimum amount of token occurances needed for an n-gram to be included\n",
    "    #\n",
    "    def add_n_grams(self, n=2, min_count=1):\n",
    "        logging.info('Performing normalization.')\n",
    "        logging.debug('n=' + str(n))\n",
    "        logging.debug('min_count=' + str(min_count))\n",
    "\n",
    "        logging.info('Adding 2-grams')\n",
    "        bigram = Phrases(self.corpus, min_count=min_count, delimiter=b' ')\n",
    "        \n",
    "        if n == 3:\n",
    "            logging.info('Adding 3-grams')\n",
    "            trigram = Phrases(bigram[self.corpus], min_count=1, delimiter=b' ')\n",
    "            for document in range(self.N):\n",
    "                self.corpus[document] = [n_gram for n_gram in trigram[bigram[self.corpus[document]]] \n",
    "                               if n_gram.count(' ') < n]\n",
    "        elif n == 2:\n",
    "            for document in range(self.N):\n",
    "                self.corpus[document] = [n_gram for n_gram in bigram[self.corpus[document]]\n",
    "                               if n_gram.count(' ') < n]\n",
    "        else:\n",
    "            logging.warning('Invalid parameter! Skipping n-grams...')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Remove stop-words\n",
    "    # params:\n",
    "    #   stop<list([string])>: A list containing all stop words to exclude\n",
    "    #\n",
    "    def remove_stop_words(self, stop=stopwords.words('english')):\n",
    "        logging.info('Removing stop-words and n-grams with stop-words.')\n",
    "        logging.debug('stop_words=' + str(stop))\n",
    "        \n",
    "        # Filter out any token containing a stop-word\n",
    "        self.corpus = [[token for token in document\n",
    "                            if all(token_part not in stop \n",
    "                                   for token_part in token.split())\n",
    "                       ] for document in self.corpus]\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Prepare the corpus for topic modelling\n",
    "    #\n",
    "    def preprocess(self):\n",
    "        logging.info('Pipeline step 2: Preprocessing')\n",
    "        self.tokenize()\n",
    "        self.normalize()\n",
    "        self.filter_length(min_strlen=3)\n",
    "        self.filter_match(pattern=r'\\w*?[a-zA-Z]\\w*')\n",
    "        self.lowercase()\n",
    "        self.add_n_grams(n=3)\n",
    "        self.remove_stop_words(stop=stopwords.words('english') + ['use', 'also'])\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Transform lists of pre-processed tokens into an id: word frequency representation\n",
    "    # params:\n",
    "    #   no_below<integer>: The minimum amount of documents a word must appear in to be considered\n",
    "    #   no_above<float>: The maximum % of documents a word may appear in to be considered\n",
    "    #\n",
    "    def generate_dict(self, no_below=100, no_above=0.5):\n",
    "        logging.info('Generating a dictionary of the corpus.')\n",
    "        logging.debug('no_below=' + str(no_below))\n",
    "        logging.debug('no_above=' + str(no_above))\n",
    "        \n",
    "        self.dictionary = corpora.Dictionary(self.corpus)\n",
    "\n",
    "        # Filter out rare and common tokens\n",
    "        self.dictionary.filter_extremes(no_below=no_below, no_above=no_above)\n",
    "        return\n",
    "        \n",
    "    \n",
    "    # Transforms lists of pre-processed tokens into a bag of words representation\n",
    "    #\n",
    "    def generate_bow(self):\n",
    "        logging.info('Generating a Bag of Words representation of the corpus.')\n",
    "        \n",
    "        # Generate the bag of words\n",
    "        self.corpus = [self.dictionary.doc2bow(documents) for documents in self.corpus]\n",
    "\n",
    "        logging.debug('Number of unique tokens: ' + str(len(self.dictionary)))\n",
    "        logging.debug('Number of documents: ' + str(len(self.corpus)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Save a frozen, trained topic model to disk\n",
    "    # params:\n",
    "    #   path<string>: The path to the save location for the model\n",
    "    #\n",
    "    def save_model(self, path='model.gensim'):\n",
    "        logging.info('Saving the current model at: ' + str(path))\n",
    "        self.model.save(path)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for running LDA to do topic modelling\n",
    "#\n",
    "class LDA(TopicModeler):\n",
    "    # Initialize an instance of the LDA class\n",
    "    # params:\n",
    "    #   corpus<numpy.ndarray([string])>: A numpy array of strings, representing documents in a corpus\n",
    "    #   num_topics<integer>: The amount of hidden topics in the corpus\n",
    "    #   disp_interval<integer>: Display progess after each interval\n",
    "    #\n",
    "    def __init__(self, corpus, num_topics=5, disp_interval=1000):\n",
    "        super().__init__(corpus, disp_interval)\n",
    "        \n",
    "        self.num_topics = num_topics\n",
    "        logging.info('Initialized an LDA with num_topics=' + str(self.num_topics))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # A setter for the parameter representing the number of latent semantic topics to model\n",
    "    # params:\n",
    "    #   num_topics<integer>: The amount of hidden topics in the corpus\n",
    "    #\n",
    "    def set_num_topics(self, num_topics):\n",
    "        logging.debug('Set num_topics=' + str(self.num_topics))\n",
    "        self.num_topics = num_topics\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Train an LDA model on the corpus\n",
    "    # params:\n",
    "    #   batch_size<integer>: The amount of documents to be processed at a time\n",
    "    #   epochs<integer>: The amount of complete passes through the dataset before completing training\n",
    "    #   iterations<integer>: Maximum iterations on the corpus before inferring a topic distribution\n",
    "    #   eval_every<boolean>: Evaluate the log perplexity of the model (2x hit to training time)\n",
    "    #   eta<string|list>: The dirichlet prior for topic-word distributions\n",
    "    #   alpha<string|list>: The dirichlet piror for document-topic distributions\n",
    "    #\n",
    "    def train(self, batch_size=1000, epochs=10, iterations=400, eval_every=None, eta='auto', alpha='auto'):\n",
    "        logging.info('Training the LDA model.')\n",
    "        logging.debug('batch_size=' + str(batch_size))\n",
    "        logging.debug('epochs=' + str(epochs))\n",
    "        logging.debug('iterations=' + str(iterations))\n",
    "        logging.debug('eval_every=' + str(eval_every))\n",
    "        \n",
    "        self.model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=self.corpus, \n",
    "            id2word=self.dictionary, \n",
    "            num_topics=self.num_topics, \n",
    "            passes=epochs, \n",
    "            iterations=iterations, \n",
    "            chunksize=batch_size,\n",
    "            alpha=alpha, eta=eta,\n",
    "            eval_every=eval_every\n",
    "        )\n",
    "        for (i, z) in zip(range(self.num_topics), self.model.print_topics(num_words=self.num_topics)):\n",
    "            logging.debug('Topic #' + str(i) + \": \" + str(z))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # Retrieve set of topics for a document from a trained LDA model\n",
    "    # params:\n",
    "    #   document<integer>: The index of the document for which topics will be retrieved\n",
    "    # returns: <type>: TODO\n",
    "    #\n",
    "    def get_document_topics(self, document=0):\n",
    "        return self.model.get_document_topics(self.corpus[document])\n",
    "    \n",
    "    \n",
    "    # Calculate the topic coherence for an LDA model\n",
    "    # This is the sum of topic coherences of all topics, divided by the number of topics\n",
    "    # params:\n",
    "    #   num_topics<integer>: The amount of hidden topics in the corpus\n",
    "    # returns: <float>: The average topic coherence for this model \n",
    "    #\n",
    "    def get_coherence(self, num_topics=5):\n",
    "        top_topics = self.model.top_topics(self.corpus)\n",
    "        avg_topic_coherence = sum([z[1] for z in top_topics]) / self.num_topics\n",
    "        logging.info('Average topic coherence: ' + str(avg_topic_coherence))\n",
    "        return avg_topic_coherence\n",
    "    \n",
    "    \n",
    "    # Get the perplexity of an LDA model over the entire corpus\n",
    "    # returns: <float>: The average topic coherence for this model \n",
    "    #\n",
    "    def get_perplexity(self):\n",
    "        perplexity = self.model.log_perplexity(self.corpus)\n",
    "        logging.info('Perplexity: ' + str(perplexity))\n",
    "        return perplexity\n",
    "    \n",
    "    \n",
    "    # Pretty print the top topics for this model\n",
    "    #\n",
    "    def print_topics(self):\n",
    "        pprint(self.model.top_topics(self.corpus))\n",
    "        return\n",
    "\n",
    "    \n",
    "    # Generate an HTML page to visualize the top topic distrubutions as 2D vectors\n",
    "    # params:\n",
    "    #   path<string>: The the path to the location where this HTML page should be saved\n",
    "    #   save<boolean>: Save the HTML page or no\n",
    "    #\n",
    "    def generate_visual_LDA(self, path='lda-vis-data.html', save=False):\n",
    "        logging.info('Generating an HTML page to display the LDA topic distributions...')\n",
    "        lda_vis_data = pyLDAvis.gensim.prepare(self.model, self.corpus, self.dictionary)\n",
    "        if (save):\n",
    "            logging.info('Saving the LDA visualization at: ' + str(path))\n",
    "            pyLDAvis.save_html(lda_vis_data, path)\n",
    "        pyLDAvis.show(lda_vis_data)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of parameters for the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) IMPORT DATASET\n",
    "# Dataset is from https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv\n",
    "data = pd.read_csv('../data/metadata.csv', low_memory = False)\n",
    "keep_columns = ['publish_time', 'journal', 'abstract']\n",
    "\n",
    "# Select the relevant columns and rows from the dataset\n",
    "new_data = data[keep_columns].dropna(subset=['abstract']).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no_below and no_above\n",
    "## Within what bounds of frequency should a candidate keyword appear in order to be considered?\n",
    "repetitions = 5\n",
    "corpus_size = 10000\n",
    "num_topics = 5\n",
    "\n",
    "\n",
    "## The minimum amount of documents a word must appear in to be considered\n",
    "candidate_no_below = [1, 10, 50, 100]\n",
    "avg_coherence = []\n",
    "perplexity = []\n",
    "\n",
    "for nb in candidate_no_below:\n",
    "    logging.info('no_below=' + str(nb))\n",
    "    \n",
    "    # (2) PREPROCESS TEXT\n",
    "    lda_model = LDA(corpus=new_data[:corpus_size, -1], disp_interval=1000)\n",
    "    lda_model.set_num_topics(num_topics)\n",
    "    lda_model.tokenize()\n",
    "    lda_model.normalize()\n",
    "    lda_model.filter_length(min_strlen=3)\n",
    "    lda_model.filter_match(pattern=r'\\w*?[a-zA-Z]\\w*')\n",
    "    lda_model.lowercase()\n",
    "    lda_model.add_n_grams(n=3)\n",
    "    lda_model.remove_stop_words(stop=stopwords.words('english') + ['use', 'also'])\n",
    "\n",
    "    # (3) PROCESS TEXT\n",
    "    # (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "    lda_model.generate_dict(no_below=nb)\n",
    "    lda_model.generate_bow()\n",
    "\n",
    "    for r in range(repetitions):\n",
    "        # (3.2) BUILD THE TOPIC MODEL\n",
    "        lda_model.train()\n",
    "        lda_model.get_document_topics()\n",
    "\n",
    "        cur_coherence += lda_model.get_coherence()/repetitions\n",
    "        cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "\n",
    "    # (3.3) Log the avg coherence and perplexity\n",
    "    avg_coherence.append(cur_coherence)\n",
    "    perplexity.append(cur_perplexity)\n",
    "\n",
    "\n",
    "# (4) Visualize the results\n",
    "## Avg. Coherence\n",
    "plt.clf()\n",
    "plt.title(\"Avg. Coherence for LDA w/ Varying no_below\")\n",
    "plt.xlabel(\"no_below\") \n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.plot([str(cand) for cand in candidate_no_below], avg_coherence, color='navy', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "if not os.path.exists('../bin/LDA/'):\n",
    "    os.makedirs('../bin/LDA/')\n",
    "plt.savefig('../bin/LDA/no_below-coherence.png')\n",
    "plt.show()\n",
    "\n",
    "## Perplexity\n",
    "plt.clf()\n",
    "plt.title(\"Perplexity for LDA w/ Varying no_below\")\n",
    "plt.xlabel(\"no_below\") \n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.plot([str(cand) for cand in candidate_no_below], perplexity, color='firebrick', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "plt.savefig('../bin/LDA/no_below-perplexity.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The maximum % of documents a word may appear in to be considered\n",
    "candidate_no_above = [.5, .6, .7, .8]\n",
    "avg_coherence = []\n",
    "perplexity = []\n",
    "\n",
    "for na in candidate_no_above:\n",
    "    logging.info('no_above=' + str(na))\n",
    "        \n",
    "    # (2) PREPROCESS TEXT\n",
    "    lda_model = LDA(corpus=new_data[:corpus_size, -1], disp_interval=1000)\n",
    "    lda_model.set_num_topics(num_topics)\n",
    "    lda_model.tokenize()\n",
    "    lda_model.normalize()\n",
    "    lda_model.filter_length(min_strlen=3)\n",
    "    lda_model.filter_match(pattern=r'\\w*?[a-zA-Z]\\w*')\n",
    "    lda_model.lowercase()\n",
    "    lda_model.add_n_grams(n=3)\n",
    "    lda_model.remove_stop_words(stop=stopwords.words('english') + ['use', 'also'])\n",
    "    \n",
    "    # (3) PROCESS TEXT\n",
    "    # (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "    lda_model.generate_dict(no_above=na)\n",
    "    lda_model.generate_bow()\n",
    "\n",
    "    for r in range(repetitions):\n",
    "        # (3.2) BUILD THE TOPIC MODEL\n",
    "        lda_model.train()\n",
    "        lda_model.get_document_topics()\n",
    "\n",
    "        cur_coherence += lda_model.get_coherence()/repetitions\n",
    "        cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "\n",
    "    # (3.3) Log the avg coherence and perplexity\n",
    "    avg_coherence.append(cur_coherence)\n",
    "    perplexity.append(cur_perplexity)\n",
    "\n",
    "\n",
    "# (4) Visualize the results\n",
    "## Avg. Coherence\n",
    "plt.clf()\n",
    "plt.title(\"Avg. Coherence for LDA w/ Varying no_above\")\n",
    "plt.xlabel(\"no_above\") \n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.plot([str(cand) for cand in candidate_no_above], avg_coherence, color='navy', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "if not os.path.exists('../bin/LDA/'):\n",
    "    os.makedirs('../bin/LDA/')\n",
    "plt.savefig('../bin/LDA/no_above-coherence.png')\n",
    "plt.show()\n",
    "\n",
    "## Perplexity\n",
    "plt.clf()\n",
    "plt.title(\"Perplexity for LDA w/ Varying no_above\")\n",
    "plt.xlabel(\"no_above\") \n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.plot([str(cand) for cand in candidate_no_above], perplexity, color='firebrick', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "plt.savefig('../bin/LDA/no_above-perplexity.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stemming or Lemmatization? Or no morphological normalization?\n",
    "## Stemming - chop off suffixes; lemmatization - get the dictionary form of the word\n",
    "repetitions = 5\n",
    "\n",
    "corpus_size = 10000\n",
    "num_topics = 5\n",
    "\n",
    "normalization = ['none', 'stem', 'lemma']\n",
    "avg_coherence = []\n",
    "perplexity = []\n",
    "        \n",
    "        \n",
    "# Baseline - no morphological normalization   \n",
    "logging.info('norm=None')\n",
    "\n",
    "# (2) PREPROCESS TEXT\n",
    "lda_model = LDA(corpus=new_data[:corpus_size, -1], disp_interval=1000)\n",
    "lda_model.set_num_topics(num_topics)\n",
    "lda_model.tokenize()\n",
    "#lda_model.normalize()\n",
    "lda_model.filter_length(min_strlen=3)\n",
    "lda_model.filter_match(pattern=r'\\w*?[a-zA-Z]\\w*')\n",
    "lda_model.lowercase()\n",
    "lda_model.add_n_grams(n=3)\n",
    "lda_model.remove_stop_words(stop=stopwords.words('english') + ['use', 'also'])\n",
    "\n",
    "# (3) PROCESS TEXT\n",
    "# (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "lda_model.generate_dict()\n",
    "lda_model.generate_bow()\n",
    "\n",
    "\n",
    "for r in range(repetitions):\n",
    "    # (3.2) BUILD THE TOPIC MODEL\n",
    "    lda_model.train()\n",
    "    lda_model.get_document_topics()\n",
    "\n",
    "    cur_coherence += lda_model.get_coherence()/repetitions\n",
    "    cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "\n",
    "# (3.3) Log the avg coherence and perplexity\n",
    "avg_coherence.append(cur_coherence)\n",
    "perplexity.append(cur_perplexity)\n",
    "    \n",
    "    \n",
    "# Stemming\n",
    "logging.info('norm=stem')\n",
    "# (2) PREPROCESS TEXT\n",
    "lda_model = LDA(corpus=new_data[:corpus_size, -1], disp_interval=1000)\n",
    "lda_model.set_num_topics(num_topics)\n",
    "lda_model.tokenize()\n",
    "lda_model.normalize(norm='stem')\n",
    "lda_model.filter_length(min_strlen=3)\n",
    "lda_model.filter_match(pattern=r'\\w*?[a-zA-Z]\\w*')\n",
    "lda_model.lowercase()\n",
    "lda_model.add_n_grams(n=3)\n",
    "lda_model.remove_stop_words(stop=stopwords.words('english') + ['use', 'also'])\n",
    "\n",
    "# (3) PROCESS TEXT\n",
    "# (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "lda_model.generate_dict()\n",
    "lda_model.generate_bow()\n",
    "\n",
    "for r in range(repetitions):\n",
    "    # (3.2) BUILD THE TOPIC MODEL\n",
    "    lda_model.train()\n",
    "    lda_model.get_document_topics()\n",
    "\n",
    "    cur_coherence += lda_model.get_coherence()/repetitions\n",
    "    cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "\n",
    "# (3.3) Log the avg coherence and perplexity\n",
    "avg_coherence.append(cur_coherence)\n",
    "perplexity.append(cur_perplexity)\n",
    "\n",
    "\n",
    "# Lemmatization\n",
    "logging.info('norm=lemma')\n",
    "# (2) PREPROCESS TEXT\n",
    "lda_model = LDA(corpus=new_data[:corpus_size, -1], disp_interval=1000)\n",
    "lda_model.set_num_topics(num_topics)\n",
    "lda_model.tokenize()\n",
    "lda_model.normalize(norm='lemma')\n",
    "lda_model.filter_length(min_strlen=3)\n",
    "lda_model.filter_match(pattern=r'\\w*?[a-zA-Z]\\w*')\n",
    "lda_model.lowercase()\n",
    "lda_model.add_n_grams(n=3)\n",
    "lda_model.remove_stop_words(stop=stopwords.words('english') + ['use', 'also'])\n",
    "\n",
    "# (3) PROCESS TEXT\n",
    "# (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "lda_model.generate_dict()\n",
    "lda_model.generate_bow()\n",
    "\n",
    "for r in range(repetitions):\n",
    "    # (3.2) BUILD THE TOPIC MODEL\n",
    "    lda_model.train()\n",
    "    lda_model.get_document_topics()\n",
    "\n",
    "    cur_coherence += lda_model.get_coherence()/repetitions\n",
    "    cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "\n",
    "# (3.3) Log the avg coherence and perplexity\n",
    "avg_coherence.append(cur_coherence)\n",
    "perplexity.append(cur_perplexity)\n",
    "\n",
    "\n",
    "# (4) Visualize the results\n",
    "## Avg. Coherence\n",
    "plt.clf()\n",
    "plt.title(\"Avg. Coherence for LDA w/ Various Morphological Normalization\")\n",
    "plt.xlabel(\"Morphological Normalization\") \n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.plot(normalization, avg_coherence, color='navy', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "if not os.path.exists('../bin/LDA/'):\n",
    "    os.makedirs('../bin/LDA/')\n",
    "plt.savefig('../bin/LDA/normalization-coherence.png')\n",
    "plt.show()\n",
    "\n",
    "## Perplexity\n",
    "plt.clf()\n",
    "plt.title(\"Perplexity for LDA w/ Various Morphological Normalization\")\n",
    "plt.xlabel(\"Morphological Normalization\") \n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.plot(normalization, perplexity, color='firebrick', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "plt.savefig('../bin/LDA/normalization-perplexity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) PREPROCESS TEXT\n",
    "corpus_size = 10000\n",
    "lda_model = LDA(corpus=new_data[:corpus_size, -1], disp_interval=1000)\n",
    "lda_model.preprocess()\n",
    "\n",
    "# (3) PROCESS TEXT\n",
    "# (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "lda_model.generate_dict()\n",
    "lda_model.generate_bow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing num_topics\n",
    "repetitions = 5\n",
    "\n",
    "candidate_num_topics = [5, 10, 15, 20, 25, 30]\n",
    "avg_coherence = []\n",
    "perplexity = []\n",
    "\n",
    "for k in candidate_num_topics:\n",
    "    logging.info('num_topics=' + str(num_topics))\n",
    "    cur_coherence = 0\n",
    "    cur_perplexity = 0\n",
    "    lda_model.set_num_topics(k)\n",
    "    \n",
    "    # Get the average coherence and perplexity over a number of repetitions\n",
    "    for r in range(repetitions):\n",
    "        # (3.2) BUILD THE TOPIC MODEL\n",
    "        lda_model.train()\n",
    "        lda_model.get_document_topics()\n",
    "        \n",
    "        cur_coherence += lda_model.get_coherence()/repetitions\n",
    "        cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "    \n",
    "    # (3.3) Log the avg coherence and perplexity\n",
    "    avg_coherence.append(cur_coherence)\n",
    "    perplexity.append(cur_perplexity)\n",
    "\n",
    "    \n",
    "# (4) Visualize the results\n",
    "## Avg. Coherence\n",
    "plt.clf()\n",
    "plt.title(\"Avg. Coherence for LDA w/ Varying num_topics\")\n",
    "plt.xlabel(\"num_topics\") \n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.plot(candidate_num_topics, avg_coherence, color='navy', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "if not os.path.exists('../bin/LDA/'):\n",
    "    os.makedirs('../bin/LDA/')\n",
    "plt.savefig('../bin/LDA/num_topics-coherence.png')\n",
    "plt.show()\n",
    "\n",
    "## Perplexity\n",
    "plt.clf()\n",
    "plt.title(\"Perplexity for LDA w/ Varying num_topics\")\n",
    "plt.xlabel(\"num_topics\") \n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.plot(candidate_num_topics, perplexity, color='firebrick', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "plt.savefig('../bin/LDA/num_topics-perplexity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optimizing eta (the dirichlet prior for word-topic distributions)\n",
    "# Expectation: smaller eta == more focused topics; larger == more sparse topics\n",
    "repetitions = 5\n",
    "\n",
    "num_topics = 5\n",
    "lda_model.set_num_topics(num_topics)\n",
    "\n",
    "candidate_etas = [0.01, 0.1, 1, 10, 'auto']\n",
    "avg_coherence = []\n",
    "perplexity = []\n",
    "\n",
    "for eta in candidate_etas:\n",
    "    logging.info('candidate_etas=' + str(candidate_etas))\n",
    "    cur_coherence = 0\n",
    "    cur_perplexity = 0\n",
    "    \n",
    "    # Get the average coherence and perplexity over a number of repetitions\n",
    "    for r in range(repetitions):\n",
    "        # (3.2) BUILD THE TOPIC MODEL\n",
    "        lda_model.train(eta=eta)\n",
    "        lda_model.get_document_topics()\n",
    "        \n",
    "        cur_coherence += lda_model.get_coherence()/repetitions\n",
    "        cur_perplexity += lda_model.get_perplexity()/repetitions\n",
    "    \n",
    "    # (3.3) Log the avg coherence and perplexity\n",
    "    avg_coherence.append(cur_coherence)\n",
    "    perplexity.append(cur_perplexity)\n",
    "    \n",
    "# (4) Visualize the results\n",
    "## Avg. Coherence\n",
    "plt.clf()\n",
    "plt.title(\"Avg. Coherence for LDA w/ Varying eta\")\n",
    "plt.xlabel(\"eta\") \n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.plot([str(eta) for eta in candidate_etas], avg_coherence, color='navy', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "if not os.path.exists('../bin/LDA/'):\n",
    "    os.makedirs('../bin/LDA/')\n",
    "plt.savefig('../bin/LDA/eta-coherence.png')\n",
    "plt.show()\n",
    "\n",
    "## Perplexity\n",
    "plt.clf()\n",
    "plt.title(\"Perplexity for LDA w/ Varying eta\")\n",
    "plt.xlabel(\"eta\") \n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.plot([str(eta) for eta in candidate_etas], perplexity, color='firebrick', linewidth=2, label=\"LDA\")\n",
    "plt.legend()\n",
    "plt.savefig('../bin/LDA/eta-perplexity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing LDA on various subsets of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALL ABSTRACTS\n",
    "# (1) IMPORT DATASET\n",
    "# Dataset is from https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge?select=metadata.csv\n",
    "data = pd.read_csv('../data/metadata.csv', low_memory = False)\n",
    "keep_columns = ['publish_time', 'journal', 'abstract']\n",
    "\n",
    "# Select the relevant columns and rows from the dataset\n",
    "new_data = data[keep_columns].dropna(subset=['abstract']).to_numpy()\n",
    "\n",
    "# (2) PREPROCESS TEXT\n",
    "lda_model = LDA(corpus=new_data[:, -1], num_topics=5)\n",
    "lda_model.preprocess()\n",
    "\n",
    "# (3) PROCESS TEXT\n",
    "# (3.1) CREATE THE DICTIONARY AND BAG-OF-WORDS REPRESENTATION OF THE CORPUS\n",
    "lda_model.generate_dict()\n",
    "lda_model.generate_bow()\n",
    "if not os.path.exists('../bin/LDA/'):\n",
    "    os.makedirs('../bin/LDA/')\n",
    "\n",
    "# (3.2) BUILD THE TOPIC MODEL\n",
    "lda_model.train()\n",
    "lda_model.save_model(path='../bin/LDA/all_model.gensim')\n",
    "lda_model.get_document_topics()\n",
    "lda_model.get_coherence()\n",
    "lda_model.get_perplexity()\n",
    "\n",
    "# (4) ANALYZE THE DATA\n",
    "lda_model.print_topics()\n",
    "lda_model.generate_visual_LDA(path='../bin/LDA/all_lda-vis-data.html', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By journal []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By years []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
